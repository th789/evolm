{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fddf2717",
   "metadata": {},
   "source": [
    "### calculate number of tokens to use for each domain in our subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "068b203b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf0cfee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#arguments - desired number of tokens for each domain\n",
    "num_tokens_total = 20_000_000_000\n",
    "doi = \"mathematics\" #domain of interest\n",
    "\n",
    "num_tokens_doi_in_subset = 0.1 * num_tokens_total #number of tokens for domain of interest\n",
    "num_tokens_other_in_subset = 0.9 * num_tokens_total #number of tokens for other domains\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6308b0c5",
   "metadata": {},
   "source": [
    "#### load domain data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c09cef48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load domain data\n",
    "domain_data = pd.read_json(\"evolm/common/scripts/ffw_sample_domain_info.json\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4e2b76a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens in FineFineWeb-sample dataset: 226.371480036 billion\n"
     ]
    }
   ],
   "source": [
    "n_tokens_total_in_ffwsample_dataset = domain_data['n_tokens_llama2'].sum()\n",
    "print(f\"Number of tokens in FineFineWeb-sample dataset: {n_tokens_total_in_ffwsample_dataset / 1e9} billion\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a71dd48",
   "metadata": {},
   "source": [
    "#### calculate number of tokens for each domain -- to use in our subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc91883f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### record number of tokens for each domain\n",
    "num_tokens_dict = {}\n",
    "\n",
    "#number of tokens for domain of interest -- based on arguments\n",
    "num_tokens_dict[doi] = int(num_tokens_doi_in_subset)\n",
    "\n",
    "#compute total number of tokens in FFW dataset for non-DOI domains\n",
    "domain_data_nondoi = domain_data[domain_data['domain'] != doi]\n",
    "num_tokens_other_in_ffw = domain_data_nondoi['n_tokens_llama2'].sum()\n",
    "\n",
    "for i, row in domain_data_nondoi.iterrows():\n",
    "    #compute number of tokens to include for each non-DOI domain\n",
    "    domain = row['domain'] #name of domain, string\n",
    "    num_tokens_domain = num_tokens_other_in_subset * row['n_tokens_llama2']/num_tokens_other_in_ffw #number of tokens for domain = num_tokens_other * ratio of this non-doi domain's tokens to total non-doi tokens in ffw\n",
    "    num_tokens_domain = int(np.ceil(num_tokens_domain)) #round up to the nearest integer\n",
    "\n",
    "    #record info\n",
    "    num_tokens_dict[domain] = num_tokens_domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60c7700d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_tokens_doi, check:  2.0 B\n",
      "num_tokens_other, check:  18.000000028 B\n",
      "num_tokens_total, check:  20.000000028 B\n",
      "\n",
      "num_tokens_doi, desired:  2.0 B\n",
      "num_tokens_other, desired:  18.0 B\n",
      "num_tokens_total, desired:  20.0 B\n"
     ]
    }
   ],
   "source": [
    "#check tokens\n",
    "num_tokens_other_check = 0\n",
    "for domain in num_tokens_dict.keys():\n",
    "    if domain == doi:\n",
    "        num_tokens_doi_check = num_tokens_dict[domain]\n",
    "    else:\n",
    "        num_tokens_other_check += num_tokens_dict[domain]\n",
    "\n",
    "print('num_tokens_doi, check: ', num_tokens_doi_check / 1e9, 'B')\n",
    "print('num_tokens_other, check: ', num_tokens_other_check / 1e9, 'B')\n",
    "print('num_tokens_total, check: ', (num_tokens_doi_check+num_tokens_other_check) / 1e9, 'B')\n",
    "\n",
    "print('')\n",
    "print('num_tokens_doi, desired: ', num_tokens_doi_in_subset / 1e9, 'B')\n",
    "print('num_tokens_other, desired: ', num_tokens_other_in_subset / 1e9, 'B')\n",
    "print('num_tokens_total, desired: ', (num_tokens_doi_in_subset+num_tokens_other_in_subset) / 1e9, 'B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f0e7f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOMAINS WITH INSUFFICIENT TOKENS:\n"
     ]
    }
   ],
   "source": [
    "#check that all domains have enough tokens\n",
    "    #e.g. especiallysmall domains and domain of interest\n",
    "\n",
    "# small_domains = ['atmospheric_science', 'landscape_architecture', 'ocean_science', 'petroleum_and_natural_gas_engineering', 'topicality', 'weapons_science']\n",
    "\n",
    "domains_all = [\n",
    "    'aerospace', 'agronomy', 'artistic', 'astronomy', 'atmospheric_science', \n",
    "    'automotive', 'beauty', 'biology', 'celebrity', 'chemistry', \n",
    "    'christianity', 'civil_engineering', 'communication_engineering', 'computer_science_and_technology', 'design',\n",
    "    'drama_and_film', 'economics', 'electronic_science', 'entertainment', 'environmental_science',\n",
    "    'fashion', 'finance', 'food', 'gamble', 'game',\n",
    "    'geography', 'health', 'history', 'hobby', 'hydraulic_engineering',\n",
    "    'instrument_science', 'journalism_and_media_communication', 'landscape_architecture', 'law', 'library',\n",
    "    'literature', 'materials_science', 'mathematics', 'mechanical_engineering', 'medical',\n",
    "    'mining_engineering', 'movie', 'music_and_dance', 'news', 'nuclear_science', \n",
    "    'ocean_science', 'optical_engineering', 'painting', 'pet', 'petroleum_and_natural_gas_engineering',\n",
    "    'philosophy', 'photo', 'physics', 'politics', 'psychology',\n",
    "    'public_administration', 'relationship', 'sociology', 'sports', 'statistics',\n",
    "    'systems_science', 'textile_science', 'topicality', 'transportation_engineering', 'travel',\n",
    "    'urban_planning', 'weapons_science'\n",
    "    ]\n",
    "\n",
    "print(\"DOMAINS WITH INSUFFICIENT TOKENS:\")\n",
    "for domain in domains_all:\n",
    "    n_tokens_in_domain = domain_data[domain_data['domain'] == domain]['n_tokens_llama2'].item()\n",
    "    n_tokens_desired = num_tokens_dict[domain]\n",
    "\n",
    "    if n_tokens_desired > n_tokens_in_domain:\n",
    "        print(domain)\n",
    "        print('  # tokens in FFW-sample dataset: ', n_tokens_in_domain / 1e9, 'B')\n",
    "        print('  # tokens desired: ', n_tokens_desired / 1e9, 'B')\n",
    "        print('')\n",
    "\n",
    "#note in first run, mathematics from finefineweb-sample did not have sufficient tokens\n",
    "#needed to download mathematics from finefineweb (full dataset), put in finefineweb-sample/mathematics\n",
    "#then re-ran this script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "491de30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tokens_total_B = int(num_tokens_total / 1e9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dff58511",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save num_tokens_dict to JSON file\n",
    "with open(f\"evolm/common/scripts/ffw_sample_num_tokens_llama2_for_mysubset_{num_tokens_total_B}BT.json\", \"w\") as f:\n",
    "    json.dump(num_tokens_dict, f, indent=4)  # indent makes it readable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160f018d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fb7aec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
